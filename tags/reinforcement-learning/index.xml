<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Reinforcement Learning on Antonin Raffin | Homepage</title>
    <link>/tags/reinforcement-learning/</link>
    <description>Recent content in Reinforcement Learning on Antonin Raffin | Homepage</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018 - {year}</copyright>
    <lastBuildDate>Fri, 18 Oct 2019 00:00:00 +0000</lastBuildDate>
    
	    <atom:link href="/tags/reinforcement-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Stable Baselines Tutorial</title>
      <link>/talk/rl-tuto-jnrr19/</link>
      <pubDate>Fri, 18 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/talk/rl-tuto-jnrr19/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Stable Baselines Tutorial</title>
      <link>/talk/sb-ias-19/</link>
      <pubDate>Tue, 06 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/talk/sb-ias-19/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Decoupling feature extraction from policy learning: assessing benefits of state representation learning in goal based robotics</title>
      <link>/publication/decoupling/</link>
      <pubDate>Sat, 26 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/publication/decoupling/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Learning to Drive Smoothly in Minutes</title>
      <link>/project/learning-to-drive/</link>
      <pubDate>Sat, 26 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/project/learning-to-drive/</guid>
      <description>&lt;p&gt;Learning to drive smoothly in minutes, using a reinforcement learning algorithm &amp;ndash; Soft Actor-Critic (SAC) &amp;ndash; and a Variational AutoEncoder (VAE) in the Donkey Car simulator.&lt;/p&gt;

&lt;p&gt;Github repository: &lt;a href=&#34;https://github.com/araffin/learning-to-drive-in-5-minutes&#34; target=&#34;_blank&#34;&gt;https://github.com/araffin/learning-to-drive-in-5-minutes&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Blog post on &lt;a href=&#34;https://towardsdatascience.com/learning-to-drive-smoothly-in-minutes-450a7cdb35f4&#34; target=&#34;_blank&#34;&gt;Medium&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>RL Baselines Zoo</title>
      <link>/project/rl-baselines-zoo/</link>
      <pubDate>Fri, 23 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/project/rl-baselines-zoo/</guid>
      <description>&lt;p&gt;A collection of trained Reinforcement Learning (RL) agents, with tuned hyperparameters, using &lt;a href=&#34;https://github.com/hill-a/stable-baselines&#34; target=&#34;_blank&#34;&gt;Stable Baselines&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Github repository: &lt;a href=&#34;https://github.com/araffin/rl-baselines-zoo&#34; target=&#34;_blank&#34;&gt;https://github.com/araffin/rl-baselines-zoo&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Goals of this repository:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Provide a simple interface to train and enjoy RL agents&lt;/li&gt;
&lt;li&gt;Benchmark the different Reinforcement Learning algorithms&lt;/li&gt;
&lt;li&gt;Provide tuned hyperparameters for each environment and RL algorithm&lt;/li&gt;
&lt;li&gt;Have fun with the trained agents!&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>S-RL Toolbox</title>
      <link>/project/srl-toolbox/</link>
      <pubDate>Wed, 10 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/project/srl-toolbox/</guid>
      <description>

&lt;p&gt;S-RL Toolbox: Reinforcement Learning (RL) and State Representation Learning (SRL) Toolbox for Robotics.&lt;/p&gt;

&lt;p&gt;Github repository: &lt;a href=&#34;https://github.com/araffin/robotics-rl-srl&#34; target=&#34;_blank&#34;&gt;https://github.com/araffin/robotics-rl-srl&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Documentation: &lt;a href=&#34;https://s-rl-toolbox.readthedocs.io&#34; target=&#34;_blank&#34;&gt;https://s-rl-toolbox.readthedocs.io&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Paper: &lt;a href=&#34;https://arxiv.org/abs/1809.09369&#34; target=&#34;_blank&#34;&gt;https://arxiv.org/abs/1809.09369&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;main-features&#34;&gt;Main Features&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;10 RL algorithms (&lt;a href=&#34;https://github.com/hill-a/stable-baselines&#34; target=&#34;_blank&#34;&gt;Stable Baselines&lt;/a&gt; included)&lt;/li&gt;
&lt;li&gt;logging / plotting / visdom integration / replay trained agent&lt;/li&gt;
&lt;li&gt;hyperparameter search (hyperband, hyperopt)&lt;/li&gt;
&lt;li&gt;integration with State Representation Learning (SRL) methods (for feature extraction)&lt;/li&gt;
&lt;li&gt;visualisation tools (explore latent space, display action proba, live plot in the state space, &amp;hellip;)&lt;/li&gt;
&lt;li&gt;robotics environments to compare SRL methods&lt;/li&gt;
&lt;li&gt;easy install using anaconda env or Docker images (CPU/GPU)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Stable Baselines</title>
      <link>/project/stable-baselines/</link>
      <pubDate>Thu, 27 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/project/stable-baselines/</guid>
      <description>&lt;p&gt;Stable Baselines is a set of improved implementations of Reinforcement Learning (RL) algorithms based on OpenAI Baselines.&lt;/p&gt;

&lt;p&gt;Github repository: &lt;a href=&#34;https://github.com/hill-a/stable-baselines&#34; target=&#34;_blank&#34;&gt;https://github.com/hill-a/stable-baselines&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;You can read a detailed presentation of Stable Baselines in the &lt;a href=&#34;https://towardsdatascience.com/stable-baselines-a-fork-of-openai-baselines-reinforcement-learning-made-easy-df87c4b2fc82&#34; target=&#34;_blank&#34;&gt;Medium article&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>S-RL Toolbox: Environments, Datasets and Evaluation Metrics for State Representation Learning</title>
      <link>/publication/srl-toolbox/</link>
      <pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/publication/srl-toolbox/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Stable Baselines: a Fork of OpenAI Baselines — Reinforcement Learning Made Easy</title>
      <link>/post/stable-baselines/</link>
      <pubDate>Mon, 20 Aug 2018 00:00:00 +0200</pubDate>
      
      <guid>/post/stable-baselines/</guid>
      <description>&lt;p&gt;Read the full article on &lt;a href=&#34;https://towardsdatascience.com/stable-baselines-a-fork-of-openai-baselines-reinforcement-learning-made-easy-df87c4b2fc82&#34; target=&#34;_blank&#34;&gt;Medium&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Unsupervised learning of state representations for multiple tasks</title>
      <link>/publication/multiple-tasks-srl/</link>
      <pubDate>Thu, 01 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>/publication/multiple-tasks-srl/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
