<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Reinforcement Learning on Antonin Raffin | Homepage</title>
    <link>/tags/reinforcement-learning/</link>
    <description>Recent content in Reinforcement Learning on Antonin Raffin | Homepage</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Fri, 23 Nov 2018 00:00:00 +0100</lastBuildDate>
    
	<atom:link href="/tags/reinforcement-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>RL Baselines Zoo</title>
      <link>/project/rl-baselines-zoo/</link>
      <pubDate>Fri, 23 Nov 2018 00:00:00 +0100</pubDate>
      
      <guid>/project/rl-baselines-zoo/</guid>
      <description>A collection of trained Reinforcement Learning (RL) agents, with tuned hyperparameters, using Stable Baselines.
Github repository: https://github.com/araffin/rl-baselines-zoo
Goals of this repository:
 Provide a simple interface to train and enjoy RL agents Benchmark the different Reinforcement Learning algorithms Provide tuned hyperparameters for each environment and RL algorithm Have fun with the trained agents!  </description>
    </item>
    
    <item>
      <title>S-RL Toolbox</title>
      <link>/project/srl-toolbox/</link>
      <pubDate>Wed, 10 Oct 2018 00:00:00 +0200</pubDate>
      
      <guid>/project/srl-toolbox/</guid>
      <description> S-RL Toolbox: Reinforcement Learning (RL) and State Representation Learning (SRL) Toolbox for Robotics.
Github repository: https://github.com/araffin/robotics-rl-srl
Documentation: https://s-rl-toolbox.readthedocs.io
Paper: https://arxiv.org/abs/1809.09369
Main Features  10 RL algorithms (Stable Baselines included) logging / plotting / visdom integration / replay trained agent hyperparameter search (hyperband, hyperopt) integration with State Representation Learning (SRL) methods (for feature extraction) visualisation tools (explore latent space, display action proba, live plot in the state space, &amp;hellip;) robotics environments to compare SRL methods easy install using anaconda env or Docker images (CPU/GPU)  </description>
    </item>
    
    <item>
      <title>Stable Baselines</title>
      <link>/project/stable-baselines/</link>
      <pubDate>Thu, 27 Sep 2018 00:00:00 +0200</pubDate>
      
      <guid>/project/stable-baselines/</guid>
      <description>Stable Baselines is a set of improved implementations of Reinforcement Learning (RL) algorithms based on OpenAI Baselines.
Github repository: https://github.com/hill-a/stable-baselines
You can read a detailed presentation of Stable Baselines in the Medium article</description>
    </item>
    
    <item>
      <title>S-RL Toolbox: Environments, Datasets and Evaluation Metrics for State Representation Learning</title>
      <link>/publication/srl-toolbox/</link>
      <pubDate>Sat, 01 Sep 2018 00:00:00 +0200</pubDate>
      
      <guid>/publication/srl-toolbox/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Stable Baselines: a Fork of OpenAI Baselines — Reinforcement Learning Made Easy</title>
      <link>/post/stable-baselines/</link>
      <pubDate>Mon, 20 Aug 2018 00:00:00 +0200</pubDate>
      
      <guid>/post/stable-baselines/</guid>
      <description>Read the full article on Medium</description>
    </item>
    
    <item>
      <title>Unsupervised learning of state representations for multiple tasks</title>
      <link>/publication/multiple-tasks-srl/</link>
      <pubDate>Thu, 01 Sep 2016 00:00:00 +0200</pubDate>
      
      <guid>/publication/multiple-tasks-srl/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>