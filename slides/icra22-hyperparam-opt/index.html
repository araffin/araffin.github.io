<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Automatic Hyperparameter Optimization - RL Tutorial ICRA 2022</title>

		<link rel="stylesheet" href="dist/reset.css">
		<link rel="stylesheet" href="dist/reveal.css">
		<link rel="stylesheet" href="dist/theme/white.css" id="theme">
		<!-- Add DLR logo -->
		<link rel="stylesheet" href="css/dlr.css">
		<!-- Grid system: http://flexboxgrid.com/ -->
		<link rel="stylesheet" href="css/flexboxgrid.min.css">

		<!-- Theme used for syntax highlighted code -->
		<!-- <link rel="stylesheet" href="plugin/highlight/monokai.css" id="highlight-theme"> -->
		<link rel="stylesheet" href="plugin/highlight/atom-one-dark.css" id="highlight-theme">
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<header>
					www.dlr.de &middot; Antonin RAFFIN &middot; Automatic Hyperparameter Tuning &middot; RL Tutorial ICRA 2022 &middot; 25.05.2022
				</header>
				<section data-background-image="images/bg_front.jpg">
					<h2>Automatic<br> Hyperparameter Tuning</h2>
				</section>
				<section>
					<h3>Motivation</h3>
					<ul class="medium-text">
						<li class="fragment">Fair comparison with baselines <sup>1,2</sup></li>
						<li class="fragment">Automatic tuning (no more grad student descent!)</li>
						<li class="fragment">Improve performance/training time</li>
					</ul>

					<p class="small-text" style="margin-top: 10%">
						<sup>1</sup>
						<a href="https://media.neurips.cc/Conferences/NIPS2018/Slides/jpineau-NeurIPS-dec18-fb.pdf">
							Reproducible, Reusable, and Robust Reinforcement Learning
						</a>
						<br>
						<sup>2</sup>
						<a href="https://arxiv.org/abs/1707.05589">
							On the State of the Art of Evaluation in Neural Language Models
						</a>
					</p>
				</section>
				<section>
					<h3>Outline</h3>
					<ol class="medium-text">
						<li>
							Hyperparameter Optimization: "n vs B/n" tradeoff
						</li>
						<li>
							Samplers
							<!-- Sampling Algorithms -->
						</li>
						<li>
							Schedulers
						</li>
						<li>
							In Practice (Optuna)
						</li>
					</ol>
				</section>
				<section>
					<h3>"n vs B/n" tradeoff</h3>
					<div class="row medium-text fragment" style="text-align: left;">
						<div class="col-xs-6">
								n: number of configurations <br>
								B / n: budget per configuration <br>
								<!-- Think "exploration vs exploitation" -->
						</div>
					</div>
					<div class="row medium-text fragment" style="text-align: left; margin-top:2%">
						<div class="col-xs-12">
								Main components: <b>sampler</b> (search algo) and <b>pruner</b> (scheduler)
						</div>
					</div>
					<div class="row">
						<div class="col-xs-12">
							<img src="images/successive_halving_comment.png" alt="" width="75%">
						</div>
					</div>
				</section>

				<section>
					<section>
						<h3>Samplers</h3>
					</section>
					<section>
						<!-- <h3>Objective Landscape</h3> -->
						<div class="row">
							<div class="col-xs-12">
								<img src="images/perf_landscape.png" alt="">
							</div>
						</div>
					</section>
					<section>
						<h4>Grid Search?</h4>
						<div class="row">
							<div class="col-xs-12">
								<img src="images/grid_search_comb.png" alt="">
							</div>
						</div>
					</section>
					<section>
						<h4>Grid Search vs Random Search</h4>

						<div class="row">
							<div class="col-xs-12">
								<img src="images/grid_vs_rs.png" alt="">
							</div>
						</div>

						<p class="small-text" style="margin-top: 1%">
							<sup>1</sup>
							<a href="https://www.jmlr.org/papers/v13/bergstra12a.html">
								Random Search for Hyper-Parameter Optimization
							</a>
							<br>
							<sup>2</sup>
							<a href="https://papers.nips.cc/paper/2011/hash/86e8f7ab32cfd12577bc2619bc635690-Abstract.html">
								Algorithms for Hyper-Parameter Optimization
							</a>
						</p>
					</section>

					<section>
						<!-- TODO: remove title from images -->
						<h4>Bayesian Optimization</h4>
						<div class="row middle-xs">
							<div class="col-xs-6">
								<ul class="medium-text">
									<li>Gaussian Process (GP)</li>
									<li>Tree of Parzen Estimators (TPE)</li>
								</ul>
							</div>
							<div class="col-xs-6">
								<img src="images/bayesian_optim.png" alt="" width="80%">
							</div>
						</div>
						<div class="row">
							<div class="col-xs-12">
								<p class="small-text">
									<sup>1</sup>
									<a href="https://link.springer.com/chapter/10.1007/978-3-030-05318-5_1">
										Hyperparameter Optimization
									</a>
								</p>
							</div>

						</div>

					</section>
					<section>
						<h4>Black box optimization</h4>
						<ul class="medium-text">
							<li>Evolution Strategies (ES, CMA-ES)</li>
							<li>Particle Swarm Optimization (PSO)</li>
						</ul>
					</section>

					<section>
						<h4>Questions?</h4>
					</section>
				</section>

				<section>
					<section>
						<h3>Schedulers</h3>
					</section>
					<section>
						<h4>Median Pruner</h4>
						<div class="row medium-text">
							<div class="col-xs-12">
								<p>Used in
									<a href="https://research.google/pubs/pub46180/">Google Vizier</a>
								</p>
							</div>
							<div class="col-xs-12">
								<blockquote cite="https://optuna.readthedocs.io/en/stable/reference/generated/optuna.pruners.MedianPruner.html">
									Prune if the trialâ€™s best intermediate result is worse than median of intermediate results of previous trials at the same step.
								</blockquote>
							</div>
						</div>
					</section>
					<section>
						<h4>Successive Halving</h4>

						<!-- TODO: correct figure, budget is not right -->
						<div class="row small-text middle-xs">
							<div class="col-xs-4">
								<ul>
									<li>Parameters: min resource and reduction factor</li>
									<li>More advanced: Hyperband</li>
								</ul>
							</div>
							<div class="col-xs-8">
								<img src="images/successive_halving_comment.png" alt="" width="100%">
							</div>
						</div>

					</section>

					<section>
						<h4>Questions?</h4>
					</section>
				</section>

				<section>
					<section>
						<h3>In Practice (Optuna)</h3>

						<div class="row">
							<div class="col-xs-12">
								<img src="images/optuna_logo.png" alt="" width="50%">
							</div>
							<div class="col-xs-12 medium-text">
								<ul>
									<li>Clean API (define-by-run)</li>
									<li>Good documentation</li>
									<li>Many features (samplers, pruners, multi objective, dashboard)</li>
									<li>Integration with many libraries</li>
								</ul>
							</div>
							<div class="col-xs-12 small-text" style="margin-top:4%">
								<a href="https://optuna.org/">https://optuna.org/</a>
							</div>
						</div>
					</section>

				 <section>
					 <h4>HP Tuning Steps</h4>
					 <ol class="medium-text">
						 <li class="fragment">Define the search space</li>
						 <li class="fragment">Define the objective function</li>
						 <li class="fragment">Choose sampler and pruner</li>
						 <li class="fragment">Get a coffee/Take a nap</li>
					 </ol>

					 <p class="small-text fragment" style="margin-top:4%">Note: Automatic hyperparameter tuning is included in the RL Zoo</p>
				 </section>
				 <section>
					 <h4>Search Space</h4>
					 <div class="row">
						 <div class="col-xs-12 medium-text">
							 <pre><code data-trim data-line-numbers="1|3|5-6|7-8|9-11|" class="python">
								 import optuna

								 def sample_ppo_params(trial: optuna.Trial) -> Dict[str, Any]:
										 """Sampler for PPO hyperparameters."""
										 # Sample from a list of choices (discrete)
										 activation_fn = trial.suggest_categorical("activation_fn", ["tanh", "relu"])
										 # Sample an integer in [low, high]
										 n_steps = trial.suggest_int("n_steps", 64, 2048)
										 # Sample a float in [low, high)
										 # (using log uniform distribution)
										 learning_rate = trial.suggest_float("lr", 1e-5, 1, log=True)
										 return {
											 "activation_fn": activation_fn,
											 "n_steps": n_steps,
											 "learning_rate": learning_rate,
										 }
							 </code></pre>

						 </div>
					 </div>

				 </section>

				 <section>
					 <h4>RL Objective Function (1/2)</h4>
					 <div class="row">
						 <div class="col-xs-12 medium-text">
							 <pre><code data-trim data-line-numbers="1-4|7|8-9|11-12|13-16|" class="python">
								 from stable_baselines3.common.callbacks import BaseCallback

								 class TrialEvalCallback(BaseCallback):
								 """Callback used for evaluating and reporting a trial."""

								 def _on_step(self) -> bool:
										 if self.eval_freq > 0 and self.n_calls % self.eval_freq == 0:
												 # Evaluate the current policy
												 mean_reward, _ = evaluate_policy(self.model, self.eval_env)
												 self.eval_idx += 1
												 # Send report to Optuna
												 self.trial.report(mean_reward, self.eval_idx)
												 # Prune trial if needed
												 if self.trial.should_prune():
														 self.is_pruned = True
														 return False
										 return True
							 </code></pre>

						 </div>
					 </div>

				 </section>

				 <section>
					 <h4>RL Objective Function (2/2)</h4>
					 <div class="row">
						 <div class="col-xs-12 medium-text">
							 <pre><code data-trim data-line-numbers="1|3-6|8-16|18|20-23|" class="python">
								 def objective(trial: optuna.Trial) -> float:
										 ...
										 # Sample hyperparameters
										 DEFAULT_HYPERPARAMS.update(sample_ppo_params(trial))
										 # Create the RL model
										 model = PPO(**kwargs)

										 # Create the callback that will periodically evaluate
										 # and report the performance
										 eval_callback = TrialEvalCallback(
												 eval_env,
												 trial,
												 N_EVAL_EPISODES,
												 EVAL_FREQ,
												 deterministic=True,
										 )

										 model.learn(N_TIMESTEPS, callback=eval_callback)

										 if eval_callback.is_pruned:
										 		raise optuna.exceptions.TrialPruned()

										 return eval_callback.last_mean_reward
							 </code></pre>

						 </div>
					 </div>

				 </section>

				 <section>
					 <h4>Choose Sampler, Pruner and launch the study!</h4>
					 <div class="row">
						 <div class="col-xs-12 medium-text">
							 <pre><code data-trim data-line-numbers="1-7|9-12|14-19|" class="python">
								 from optuna.pruners import MedianPruner
								 from optuna.samplers import TPESampler, RandomSampler

								 # Select the sampler, can be random, TPESampler, CMAES, ...
								 sampler = TPESampler(n_startup_trials=5)
								 # Do not prune before 1/3 of the max budget is used
								 pruner = MedianPruner(n_startup_trials=5, n_warmup_steps=N_EVALUATIONS // 3)

								 # Create the study and start the hyperparameter optimization
								 study = optuna.create_study(sampler=sampler, pruner=pruner, direction="maximize")
								 # This script can be launch in parallel when using a database
								 study.optimize(objective, n_trials=N_TRIALS, timeout=TIMEOUT)

								 # Best result
								 best_trial = study.best_trial
								 # Pandas dataframe with all the results
								 study.trials_dataframe().to_csv("study_results_ppo.csv")
								 # Plot utils
								 plot_optimization_history(study)
							 </code></pre>

						 </div>
					 </div>

				 </section>

				 <section>
					 <h4>Common Pitfalls</h4>
					 <ul class="medium-text">
						 <!-- Take a look at the RL Zoo, many tuned hyperparameters available
							 training longer may just be the solution
						 -->
						 <li class="fragment">HP optimization not needed (train longer first)</li>
						 <!-- noisy -> multiple evaluations (or afterward) -->
						 <li class="fragment">Noisy evaluation: multiple eval</li>
						 <li class="fragment">Search space too small/wide</li>
						 <li class="fragment">Slow optimization: smaller budget</li>
						 <li class="fragment">Training not stable: manual tweaks</li>
					 </ul>

				 </section>

				 <section>
					 <h4>Questions?</h4>
				 </section>

				</section>

				<section>
					<h4>Recap</h4>
					<ul class="medium-text">
						<li>Use automatic tuning when possible/needed</li>
						<li>Automatic tuning = sampler + pruner + objective function</li>
						<li>Do not use grid search</li>
						<li>Common pitfalls</li>
					</ul>
				</section>

				<section>
					<h4>What's next?</h4>

					<p class="medium-text">Practical session with Colab notebook</p>
				</section>

				<!-- <section>
					<h4>References</h4>
					<ul class="small-text">
						<li>
							<a href="https://media.neurips.cc/Conferences/NIPS2018/Slides/jpineau-NeurIPS-dec18-fb.pdf">
								Reproducible, Reusable, and Robust Reinforcement Learning
							</a>
						</li>
					</ul>
				</section> -->
			</div>
		</div>

		<script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script src="plugin/math/math.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				// Display the page number of the current slide
				slideNumber: true,

				// Add the current slide number to the URL hash so that reloading the
				// page/copying the URL will return you to the same slide
				hash: true,

				// Push each slide change to the browser history. Implies `hash: true`
				// history: false,

				// math: {
				// 	mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
				// 	config: 'TeX-AMS_HTML-full'  // See http://docs.mathjax.org/en/latest/config-files.html
				// 	// pass other options into `MathJax.Hub.Config()`
				// 	// TeX: { Macros: macros }
				// },

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealMath]
			});
		</script>
	</body>
</html>
