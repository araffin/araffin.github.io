<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

        <title>Stable-Baselines3 (SB3) Tutorial: Getting Started With Reinforcement Learning</title>

        <link rel="stylesheet" href="dist/reset.css">
        <link rel="stylesheet" href="dist/reveal.css">
        <link rel="stylesheet" href="dist/theme/white.css" id="theme">
        <!-- Add DLR logo -->
        <link rel="stylesheet" href="css/dlr.css">
        <!-- Grid system: http://flexboxgrid.com/ -->
        <link rel="stylesheet" href="css/flexboxgrid.min.css">

        <!-- Theme used for syntax highlighted code -->
        <!-- <link rel="stylesheet" href="plugin/highlight/monokai.css" id="highlight-theme"> -->
        <link rel="stylesheet" href="plugin/highlight/atom-one-dark.css" id="highlight-theme">
    </head>
    <body>
        <div class="side-block">
        </div>
        <div class="reveal">
            <div class="slides">
                <header>
                    www.dlr.de &middot; Antonin RAFFIN &middot; Stable-Baselines3 (SB3) Tutorial: Getting Started With Reinforcement Learning &middot; WAV ML-11 &middot; 30.10.2025
                </header>
                <section data-background-image="images/bg_image.jpg">
                    <div class="row bottom-xs">
                        <div class="row middle-xs">
                            <div class="col-xs-6">
                                <div class="col-xs-12">
                                    <h3 id="main-title">Stable-Baselines3 (SB3) Tutorial</h3>
                                    <p id="subtitle">Getting Started With Reinforcement Learning</p>
                                </div>
                            </div>
                            <div class="col-xs-6">
                             <img class="shadow" src="https://araffin.github.io/slides/tips-reliable-rl/images/sb3/sb_logo.png" alt="SB3 logo" style="max-width:100%;">
                            </div>
                        </div>
                        <div class="col-xs-6 xsmall-text">
                            Antonin RAFFIN (<a href="https://bsky.app/profile/araffin.bsky.social">@araffin.bsky.social</a>) <br>
                            <span class="italic">German Aerospace Center (DLR)</span><br>
                            <a href="https://araffin.github.io/">https://araffin.github.io/</a>
                        </div>
                    </div>
                </section>

                <section>
                    <h4>RL 101</h4>

                    <div class="r-stack">
                        <img class="fragment shadow" src="https://araffin.github.io/slides/updated-phd-defense-enable-rl/images/rl101/bert_surface.png">
                        <img class="fragment" src="https://araffin.github.io/slides/updated-phd-defense-enable-rl/images/rl101/bert_agent_text.png">
                        <img class="fragment" src="https://araffin.github.io/slides/updated-phd-defense-enable-rl/images/rl101/bert_env_text.png">
                        <img class="fragment" src="https://araffin.github.io/slides/updated-phd-defense-enable-rl/images/rl101/bert_rl_full.png">
                    </div>
                    <aside class="notes">
                    </aside>
                </section>

                <section>
                    <h3>Motivation</h3>
                </section>
                <section>
                    <section>
                        <h4>Adapting quickly: Retrained from Space</h4>
                        <div class="row">
                            <div class="col-xs-1">
                            </div>
                            <div class="col-xs-11">
                                <div class="videoWrapper">
                                    <iframe src="https://www.youtube.com/embed/BMFPVCu16SQ?start=180&rel=0&mute=1" allowfullscreen width="50%" height="auto" frameborder="0"></iframe>
                                </div>
                            </div>
                        </div>
                    </section>
                    <!-- RL Racing car -->
                    <section>
                        <h4>Learning to race in minutes</h4>

                        <div class="row middle-xs">
                            <div class="col-xs-12">
                                <div class="videoWrapper">
                                    <iframe src="https://www.youtube.com/embed/P_5FUlnnBUI?start=0&rel=0" allowfullscreen width="100%" height="auto" frameborder="0"></iframe>
                                </div>
                            </div>
                        </div>
                    </section>

                    <section>
                        <h4>Learning to control an elastic neck</h4>
                        <div class="row">
                            <div class="col-xs-1">
                            </div>
                            <div class="col-xs-11">
                                <div class="videoWrapper">
                                    <iframe src="https://www.youtube.com/embed/f_FmDFrYkPM?start=26&rel=0&mute=1" allowfullscreen width="50%" height="auto" frameborder="0"></iframe>
                                </div>
                            </div>
                        </div>
                    </section>
                </section>

                <section>
                    <h4>Outline</h4>
                    <ol>
                        <li style="font-weight: bold;">Getting started with Gymnasium</li>
                        <li style="color:lightgrey;">How to define a custom RL task?</li>
                        <li style="color:lightgrey;">Getting started with SB3</li>
                    </ol>
                    <aside class="notes">
                    </aside>
                </section>

                <section>
                    <h3>What is Gymnasium? (1/2)</h3>
                    <div class="row">
                        <div class="col-xs-12 medium-text">
                            <p>An Interface</p>
                        </div>
                        <div class="col-xs-12 medium-text">
                            <pre class="fragment"><code data-trim data-line-numbers="1-4|5-6|8-9|11-14|16-17|" class="python">
                                import gymnasium as gym

                                # Create the environment
                                env = gym.make("CartPole-v1", render_mode="human")
                                # Reset env and get first observation
                                obs, _ = env.reset()

                                # Step in the env with random actions
                                for _ in range(100):

                                    action = env.action_space.sample()
                                    # Retrieve new observation, reward, terminations signals
                                    # and additional infos
                                    obs, reward, terminated, truncated, info = env.step(action)

                                    # End of an episode
                                    if terminated or truncated:
                                        obs, _ = env.reset()

                            </code></pre>

                        </div>
                    </div>

                </section>

                <section>
                    <h4>Live Demo</h4>
                </section>

                <section>
                    <div class="row">
                        <div class="col-xs-12" style="margin-top:2%">
                            <h3>What is Gymnasium? (2/2)</h3>
                        </div>
                        <div class="col-xs-12 medium-text">
                            <p>A collection of environments</p>
                        </div>
                        <div class="col-xs-12">
                            <a href="https://gymnasium.farama.org/environments/classic_control/">
                                <img class="" src="images/gym_envs.png" alt="" height="60%">
                            </a>
                        </div>
                    </div>
                </section>
                <section>
                    <ol>
                        <li style="color: grey;">Getting started with Gymnasium</li>
                        <li style="font-weight:bold;">How to define a custom RL task?</li>
                        <li style="color:lightgrey;">Getting started with SB3</li>
                    </ol>
                    <aside class="notes">
                    </aside>
                </section>

                <section>
                    <h4>RL in Practice: Tips and Tricks</h4>
                    <p>Full video:
                        <a href="https://www.youtube.com/watch?v=Ikngt0_DXJg&list=PL42jkf1t1F7erwWYZQ5yDErU3lEX6MeFp">
                            RL in practice YT playlist
                        </a>
                    </p>
                    <p>Today: only about how to define custom task</p>
                </section>

                <section>
                    <h3>Defining a custom task</h3>
                    <ul>
                        <li class="fragment">observation space</li>
                        <li class="fragment">action space</li>
                        <li class="fragment">reward function</li>
                        <li class="fragment">termination conditions</li>
                    </ul>
                    <aside class="notes">
                        Always start simple!
                    </aside>
                </section>

                <section>
                    <h4>RL 102</h4>
                    <div class="r-stack">
                        <img class="fragment" src="images/gym/rl101_loop.png" alt="rl 101 loop" style="max-width: 60%">
                        <img class="fragment" src="images/gym/rl102_loop_details.png" alt="rl 102 loop details" style="max-width: 65%">
                    </div>

                </section>

                <section>
                    <h3>Choosing the observation space</h3>
                    <ul>
                        <li class="fragment">start simple</li>
                        <li class="fragment">enough information to solve the task</li>
                        <li class="fragment">do not break Markov assumption</li>
                        <li class="fragment">normalize!</li>
                    </ul>
                    <aside class="notes">
                        normalize especially for PPO/A2C + running average when you don't know the limits in
                        advance (VecNormalize) <br>
                    </aside>
                </section>

                <section>
                    <h3>CartPole Observation Space</h3>
                    <img src="images/gym/obs_space.png" alt="obs space" width="60%">
                    <div class="col-xs-12 medium-text">
                        <pre class="fragment"><code data-trim data-line-numbers="1-10|" class="python">
                            high = np.array(
                                [
                                    self.x_threshold * 2,
                                   np.inf,
                                    self.theta_threshold_radians * 2,
                                   np.inf,
                                ],
                                dtype=np.float32,
                            )

                            self.observation_space = gym.spaces.Box(low=-high, high=high, dtype=np.float32)
                        </code></pre>

                    </div>

                </section>

                <section>
                    <h3>Choosing the Action space</h3>
                    <ul>
                        <li class="fragment">start simple</li>
                        <li class="fragment">discrete / continuous</li>
                        <li class="fragment">complexity vs final performance</li>
                    </ul>
                    <aside class="notes">
                        depends on your task, sometimes you don't have the choice (e.g. atari games)
                        for robotics, makes more sense to use continuous action <br>
                        bigger action space: better performance at the end but may take much longer to train
                        (example: racing car) <br>
                        + trial and errors
                    </aside>
                </section>

                <section>
                    <h3>CartPole Action Space</h3>
                    <div class="col-xs-12 medium-text">
                        <pre class="fragment"><code data-trim data-line-numbers="|" class="python">
                            """
                            Actions:
                            Type: Discrete(2)

                            Num   Action
                            0     Push cart to the left
                            1     Push cart to the right
                            """
                            self.action_space = gym.spaces.Discrete(2)
                        </code></pre>

                    </div>

                </section>


                <section>
                    <h3>Choosing the reward function</h3>
                    <ul>
                        <li class="fragment">start simple</li>
                        <li class="fragment">reward shaping</li>
                        <li class="fragment">primary / secondary reward</li>
                        <li class="fragment">normalize!</li>
                    </ul>
                    <aside class="notes">
                        - reward shaping: careful with reward hacking<br>
                        - choosing weights for rewards: primary and secondary
                         look at the magnitude (ex continuity too high, it will do nothing)
                    </aside>
                </section>

                <section>
                    <h3>CartPole Reward</h3>
                    <div class="col-xs-12 medium-text">
                        <pre class="fragment"><code data-trim data-line-numbers="|" class="python">
                            if not terminated:
                                reward = 1.0
                        </code></pre>

                    </div>

                </section>

                <section>
                    <h3>Termination conditions?</h3>
                    <ul>
                        <li class="fragment">early stopping</li>
                        <li class="fragment">
                            <a href="https://araffin.github.io/slides/design-real-rl-experiments/#/9/0/0">
                                special treatment needed for timeouts
                            </a>
                        </li>
                        <li class="fragment">should not change the task (reward hacking)</li>
                    </ul>
                    <aside class="notes">
                        - early stopping: prevent the agent to explore useless regions of your env
                        make learning faster <br>
                        - careful or reward hacking: if you penalize at every steps but
                        stop the episode early if it explores unwanted regions:
                        will maximise its reward by stopping the episode early
                    </aside>
                </section>

                <section>
                    <h3>CartPole Termination</h3>
                    <div class="col-xs-12 medium-text">
                        <pre class="fragment"><code data-trim data-line-numbers="1-6|8-14|12|" class="python">
                            terminated = bool(
                                x < -self.x_threshold
                                or x > self.x_threshold
                                or theta < -self.theta_threshold_radians
                                or theta > self.theta_threshold_radians
                            )

                            # in the registration:
                            register(
                                id="CartPole-v1",
                                entry_point="gymnasium.envs.classic_control.cartpole:CartPoleEnv",
                                max_episode_steps=500,  # truncation
                                reward_threshold=475.0,
                            )
                        </code></pre>

                    </div>

                </section>

                <section>
                    <h3>Questions?</h3>
                </section>
                <section>
                    <ol>
                        <li style="color: grey;">Getting started with Gymnasium</li>
                        <li style="color:grey;">How to define a custom RL task?</li>
                        <li style="font-weight:bold;">Getting started with SB3</li>
                    </ol>
                    <aside class="notes">
                    </aside>
                </section>

                <section>
                    <section>
                        <h3>RL is Hard (Episode #4352)</h3>
                        <div class="row middle-xs">
                            <div class="col-xs-6">
                                <img src="https://araffin.github.io/slides/rlvs-tips-tricks/images/a2c.png" alt="A2C" style="max-width: 100%">
                                <p class="xsmall-text caption">Which algorithm is better?</p>
                            </div>
                            <div class="col-xs-6">
                                <p class="medium-text fragment">
                                    The only difference: the epsilon value to avoid division by zero in the optimizer
                                    (one is <code class="medium-text">eps=1e-7</code>
                                    the other <code class="medium-text">eps=1e-5</code>)
                                </p>
                            </div>
                        </div>
                        <aside class="notes">
                            A and B are actually the same RL algorithm (A2C),
                            sharing the exact same code, same hardware, same hyperparameters...
                            except the epsilon value to avoid division by zero in the optimizer
                        </aside>
                    </section>
                    <section>
                        <h4>RL is Hard (Episode #5623)</h4>
                        <img src="./images/ppo_sb3_sbx.png" style="max-width: 80%; margin-bottom: 0;" alt="">
                        <p class="medium-text">There is only one line of code that is different.</p>
                    </section>
                </section>


                <section>
                    <section>
                        <h4>Stable-Baselines3 (SB3)</h4>
                        <div class="row">
                        <div class="col-xs-12">
                            Reliable RL Implementations
                        </div>

                        </div>
                        <div class="row">
                        <div class="col-xs-4">
                            <img src="https://araffin.github.io/slides/tips-reliable-rl/images/sb3/sb_logo.png" class="shadow" alt="" style="max-width:100%">
                        </div>
                        <div class="col-xs-8">
                            <img src="https://araffin.github.io/slides/write-easy-to-use-robot-software/images/Stable-Baselines3-Demo.svg" alt="" style="max-width:80%">
                        </div>
                        </div>

                        <p class="medium-text">
                        <a href="https://github.com/DLR-RM/stable-baselines3">https://github.com/DLR-RM/stable-baselines3</a>
                        </p>
                        <p class="xsmall-text">
                            Raffin, Antonin, et al. "Stable-baselines3: Reliable reinforcement learning implementations." JMLR (2021)
                        </p>

                        <aside class="notes">
                        What it is? Why is it there? <br>
                        Trusted implementations <br>
                        Software used throughout the thesis
                        </aside>
                    </section>
                    <section>
                        <h4>Reliable Implementations?</h4>

                        <img src="https://araffin.github.io/slides/tips-reliable-rl/images/sb3/all_green.png" style="max-width: 50%" alt="">

                        <ul class="medium-text">
                            <li class="fragment">Performance checked</li>
                            <li class="fragment">Software best practices (96% code coverage, type checked, ...)</li>
                            <!-- <li class="fragment">3 types of tests (run, unit tests, performance)</li> -->
                            <li class="fragment">Active community (11k+ stars, 3700+ citations, 12M+ downloads)</li>
                            <li class="fragment">Fully documented</li>
                        </ul>
                        <aside class="notes">
                            Maybe mention that we have different type of tests
                            (run, unittest, performance)
                        </aside>
                    </section>
                </section>

                <section>
                    <h3>Getting Started with SB3</h3>
                    <div class="row medium-text">
                        <pre><code class="python" data-trim data-line-numbers="1-6|8-9|11-12|14-15|16-19|">
                            import gymnasium as gym
                            from stable_baselines3 import SAC

                            # Train an agent using Soft Actor-Critic on Pendulum-v1
                            env = gym.make("Pendulum-v1")
                            model = SAC("MlpPolicy", env, verbose=1)

                            # Train the model
                            model.learn(total_timesteps=20_000)

                            # Save the model
                            model.save("sac_pendulum")

                            # Load the trained model
                            model = SAC.load("sac_pendulum")
                            # Start a new episode
                            obs, _ = env.reset()
                            # What action to take in state `obs`?
                            action, _ = model.predict(obs, deterministic=True)
                        </code></pre>

                    </div>
                </section>

                <section>
                    <h4>Reproducible Reliable RL: SB3 + RL Zoo</h4>
                    <img src="https://araffin.github.io/slides/updated-phd-defense-enable-rl/images/outlook/sb3_rl_zoo.png" alt="">
                    <aside class="notes">
                        What am I using to run RL experiment?<br>
                        RL Zoo: log everything that is needed to reproduce/compare automatically <br>
                        Minimize potential mistake when running experiments <br>
                    </aside>

                </section>

                <section>
                    <section>
                        <h4>SBX: A Faster Version of SB3</h4>
                        <div class="row fragment">
                            <div class="col-xs-12">
                                <img src="https://araffin.github.io/slides/updated-phd-defense-enable-rl/images/sb3_vs_sbx.png" alt="SB3 vs SBX" style="max-width: 80%">
                            </div>
                        </div>
                        <div class="row">
                            <div class="col-xs-12">
                                <p class="medium-text">
                                    Stable-Baselines3 (PyTorch) vs SBX (Jax)
                                </p>
                            </div>
                        </div>
                        <aside class="notes">
                            JAX: DL lib with functional prog design<br>
                            JIT: huge boost if written correctly<br>
                            Here, same algo/task/hyperparams, Jax JIT is the difference.
                        </aside>
                    </section>

                    <section>
                        <h4>More gradient steps to improve sample efficiency</h4>
                        <!--<h4>More gradient steps: <code>DroQ</code></h4>-->
                        <!--<p class="medium-text">Droq</p>-->

                        <div class="row fragment">
                            <div class="col-xs-12">
                                <img src="https://araffin.github.io/slides/updated-phd-defense-enable-rl/images/droq_vs_sac.png" alt="DroQ vs SAC" style="max-width: 80%">
                            </div>
                        </div>
                        <aside class="notes">
                            Jax faster, more gradient steps, more sample efficient <br>
                            Also take a look at TQC, TD7 and CrossQ
                        </aside>
                    </section>

                    <section>
                        <h4>RL from scratch in 10 minutes</h4>
                        <div class="row middle-xs">
                            <div class="col-xs-12">
                                <video src="https://b2drop.eudat.eu/s/jaaGy4eQy6kkzek/download" controls muted></video>
                            </div>
                        </div>
                        <div class="row">
                            <div class="col-xs-12">
                                <p class="small-text">Using SB3 + Jax = SBX:
                                    <a href="https://github.com/araffin/sbx">https://github.com/araffin/sbx</a>
                                </p>
                            </div>
                        </div>
                        <aside class="notes">
                            This uses everything I presented before<br>
                            SB3 + SBX + RL Zoo
                        </aside>
                    </section>
                </section>

                <!--<section>
                    <h4>Conclusion</h4>
                    <div class="row">
                        <div class="col-xs-12">
                            <ul class="">
                                <li class="fragment">Gymnasium: an API for RL envs</li>
                                <li class="fragment">Defining a custom task</li>
                                <li class="fragment">SB3: easy to use RL implementations</li>
                            </ul>
                        </div>

                    </div>
                    <aside class="notes">
                    </aside>
                </section>-->

                <section>
                    <h4>Recap</h4>
                    <img src="images/gym/rl_recap.png" alt="rl recap" style="max-width: 70%">
                </section>

                <section>
                    <h3>Questions?</h3>
                    <div class="row middle-xs">
                        <div class="col-xs-12">
                            <video src="https://b2drop.eudat.eu/s/6QTFgtz7xemtDxy/download/bert_feedback_edited.mp4" controls muted></video>
                        </div>
                    </div>
                </section>

                <section>
                    <h4>Colab Notebook</h4>
                    <p class="medium-text">
                        <a href="https://colab.research.google.com/github/araffin/tools-for-robotic-rl-icra2022/blob/main/notebooks/icra_hands_on_sb3.ipynb">
                            https://github.com/araffin/tools-for-robotic-rl-icra2022/
                        </a>
                    </p>
                    <aside class="notes">
                    </aside>
                </section>

                <section>
                    <h4>Backup Slides</h4>
                </section>

                <section>
                    <div class="row">
                        <div class="col-xs-12">
                            <h4>RL Zoo: Reproducible Experiments</h4>
                            <p class="medium-text">
                                <a href="https://github.com/DLR-RM/rl-baselines3-zoo">
                                    https://github.com/DLR-RM/rl-baselines3-zoo
                                </a>
                            </p>
                        </div>

                    </div>
                    <div class="row medium-text">
                        <div class="col-xs-8">
                            <ul>
                                <li class="fragment">Training, loading, plotting, hyperparameter optimization</li>
                                <!-- <li class="fragment">W&B integration</li> -->
                                <li class="fragment">Everything that is needed to reproduce the experiment is logged</li>
                                <li class="fragment">200+ trained models with tuned hyperparameters</li>
                            </ul>
                        </div>
                        <div class="col-xs-4">
                            <img src="https://github.com/DLR-RM/rl-baselines3-zoo/raw/master/images/car.jpg" class="shadow" alt="">
                        </div>
                    </div>

                    <aside class="notes">
                        RL Zoo: log everything that is needed to reproduce/compare automatically <br>
                        Minimize potential mistake when running experiments <br>
                    </aside>

                </section>


                <section>
                    <h4>Plotting</h4>
                    <div class="row medium-text">
                        <div class="col-xs-12">

                        <pre style="width:100%"><code class="bash" data-line-numbers="|" data-trim>
                            python -m rl_zoo3.cli all_plots -a sac -e HalfCheetah Ant -f logs/ -o sac_results
                            python -m rl_zoo3.cli plot_from_file -i sac_results.pkl -latex -l SAC --rliable
                        </code></pre>
                    </div>
                    <div class="col-xs-12">
                        <img src="images/rl_zoo/rl_metrics.png" class="shadow" alt="">
                    </div>
                </div>
                <aside class="notes">
                    All experiments are formatted the same,<br>
                    makes it easy to plot/compare/follow best practices<br>
                </aside>

                </section>

                <section>
                    <section>
                        <div class="row">
                            <div class="col-xs-12">
                                <h4>RL Zoo: Reproducible Experiments</h4>
                                <p class="medium-text">
                                    <a href="https://github.com/DLR-RM/rl-baselines3-zoo">
                                        https://github.com/DLR-RM/rl-baselines3-zoo
                                    </a>
                                </p>
                            </div>

                        </div>
                        <div class="row medium-text">
                            <div class="col-xs-8">
                                <ul>
                                    <li class="fragment">Training, loading, plotting, hyperparameter optimization</li>
                                    <li class="fragment">W&B integration</li>
                                    <li class="fragment">200+ trained models with tuned hyperparameters</li>
                                </ul>
                            </div>
                            <div class="col-xs-4">
                                <img src="https://github.com/DLR-RM/rl-baselines3-zoo/raw/master/images/car.jpg" class="shadow" alt="">
                            </div>
                        </div>

                        <aside class="notes">
                            RL Zoo: log everything that is needed to reproduce/compare automatically <br>
                            Minimize potential mistake when running experiments <br>

                        </aside>

                    </section>
                    <section>
                        <h4>In practice</h4>
                        <div class="row medium-text">
                            <div class="col-xs-12">

                            <pre class="fragment" style="width:100%"><code class="bash" data-line-numbers="1-5" data-trim>
                                # Train an SAC agent on Pendulum using tuned hyperparameters,
                                # evaluate the agent every 1k steps and save a checkpoint every 10k steps
                                # Pass custom hyperparams to the algo/env
                                python -m rl_zoo3.train --algo sac --env Pendulum-v1 --eval-freq 1000 \
                                    --save-freq 10000 -params train_freq:2 --env-kwargs g:9.8
                            </code></pre>

                            <pre class="fragment" style="width:100%"><code class="bash" data-trim>
                                sac/
                                └── Pendulum-v1_1 # One folder per experiment
                                    ├── 0.monitor.csv # episodic return
                                    ├── best_model.zip # best model according to evaluation
                                    ├── evaluations.npz # evaluation results
                                    ├── Pendulum-v1
                                        │   ├── args.yml # custom cli arguments
                                        │   ├── config.yml # hyperparameters
                                    │   └── vecnormalize.pkl # normalization
                                    ├── Pendulum-v1.zip # final model
                                    └── rl_model_10000_steps.zip # checkpoint

                            </code></pre>
                        </div>
                    </div>

                    <aside class="notes">
                        Simple command in the terminal to launch an experiment
                        and change some parameters <br>
                        save everything for you
                    </aside>

                    </section>

                    <section>
                            <div class="row middle-xs">
                                <div class="col-xs-12">
                                    <h4>Learning to race in an hour</h4>
                                </div>
                                <div class="col-xs-12">
                                    <div class="videoWrapper">
                                        <iframe src="https://www.youtube.com/embed/ngK33h00iBE?start=0&rel=0&mute=1" allowfullscreen width="100%" height="auto" frameborder="0"></iframe>
                                    </div>
                                </div>
                            </div>
                    </section>

                    <section>
                        <h4>Hyperparameters Study - Learning To Race</h4>
                        <div class="row">
                            <div class="col-xs-12">
                                <a href="https://wandb.ai/araffin/donkeycar/reports/DonkeyCar-RL-Hyperparameters-Study--VmlldzoxODIyMDQx" target="_blank">
                                    <img src="images/wandb_study.png"
                                     alt=""
                                     class="shadow"
                                     style="max-width:70%">
                                </a>
                            </div>
                        </div>

                        <aside class="notes">
                            what matters to solve this task?<br>
                            how to isolate/keep track of changes?<br>
                            RL Zoo very helpful
                        </aside>

                    </section>


                </section>
                <section>
                    <section>
                        <h4>Combining Open-Loop Oscillators and RL</h4>
                        <div class="col-xs-12">
                            <img src="https://araffin.github.io/slides/updated-phd-defense-enable-rl/images/cpg_rl.png" class="shadow" alt="CPG RL" style="max-width:70%;"/>
                        </div>
                        <aside class="notes">
                            Reduces search space<br>
                            RL only a delta, safer, also about action space
                        </aside>
                    </section>
                    <section>
                        <h4>Learning to Exploit Elastic Actuators</h4>
                        <div class="row middle-xs">
                            <div class="col-xs-6">
                                <video src="https://b2drop.eudat.eu/public.php/dav/files/kgbBnjG5854re8m/rl_scratch.mp4" controls muted></video>
                                <p class="small-text">RL from scratch <br>
                                    0.14 m/s</p>
                            </div>
                            <div class="col-xs-6">
                                <video src="https://b2drop.eudat.eu/public.php/dav/files/kgbBnjG5854re8m/cpg_hand_tuned.mp4" controls muted></video>
                                <p class="small-text">Open-Loop Oscillators Hand-Tuned <br>
                                    0.16 m/s</p>
                            </div>

                        </div>
                        <div class="col-xs-12 xsmall-text">
                            <p>
                                Raffin et al. "Learning to Exploit Elastic Actuators for Quadruped Locomotion" 2023.
                            </p>
                        </div>
                        <aside class="notes">
                            from scratch vs with prior knowledge
                        </aside>
                    </section>
                    <section>
                        <h4>Learning to Exploit Elastic Actuators (2)</h4>
                        <div class="row middle-xs">

                        <div class="col-xs-6">
                            <video src="https://b2drop.eudat.eu/public.php/dav/files/kgbBnjG5854re8m/cpg_hand_tuned.mp4" controls muted></video>
                            <p class="small-text">Open-Loop Oscillators Hand-Tuned <br>
                                0.16 m/s</p>
                        </div>
                        <div class="col-xs-6">
                            <video src="https://b2drop.eudat.eu/public.php/dav/files/kgbBnjG5854re8m/cpg_hand_tuned_rl.mp4" controls muted></video>
                            <p class="small-text">Open-Loop Oscillators Hand-Tuned + RL <br>
                                0.19 m/s</p>
                        </div>
                        </div>
                        <div class="col-xs-12 xsmall-text">
                            <p>
                                Raffin et al. "Learning to Exploit Elastic Actuators for Quadruped Locomotion" 2023.
                            </p>
                        </div>
                        <aside class="notes">
                            from scratch vs with prior knowledge
                        </aside>
                    </section>
                    <section>
                        <h4>Learning to Exploit Elastic Actuators (2)</h4>
                        <div class="row middle-xs">

                        <div class="col-xs-6">
                            <video src="https://b2drop.eudat.eu/public.php/dav/files/kgbBnjG5854re8m/cpg_optimized.mp4" controls muted></video>
                            <p class="small-text">Open-Loop Oscillators Optimized <br>
                                0.26 m/s</p>
                        </div>
                        <div class="col-xs-6">
                            <video src="https://b2drop.eudat.eu/public.php/dav/files/kgbBnjG5854re8m/cpg_optimized_rl.mp4" controls muted></video>
                            <p class="small-text">Open-Loop Oscillators Optimized + RL <br>
                                0.34 m/s</p>
                        </div>
                        </div>
                        <div class="col-xs-12 xsmall-text">
                            <p>
                                Raffin et al. "Learning to Exploit Elastic Actuators for Quadruped Locomotion" 2023.
                            </p>
                        </div>
                        <aside class="notes">
                            from scratch vs with prior knowledge
                        </aside>
                    </section>
                    <section>
                        <div class="row">
                            <div class="col-xs-12">
                                <video src="https://b2drop.eudat.eu/s/CYyZ3faNxz98jZy/download" controls muted></video>
                            </div>
                        </div>
                    </section>

                </section>

            </div>
        </div>

        <script src="dist/reveal.js"></script>
        <script src="plugin/notes/notes.js"></script>
        <script src="plugin/markdown/markdown.js"></script>
        <script src="plugin/highlight/highlight.js"></script>
        <script src="plugin/math/math.js"></script>
        <script>
            // More info about initialization & config:
            // - https://revealjs.com/initialization/
            // - https://revealjs.com/config/
            Reveal.initialize({
                // Display the page number of the current slide
                slideNumber: true,

                // Add the current slide number to the URL hash so that reloading the
                // page/copying the URL will return you to the same slide
                hash: true,

                // Push each slide change to the browser history. Implies `hash: true`
                // history: false,

                // math: {
                // 	mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
                // 	config: 'TeX-AMS_HTML-full'  // See http://docs.mathjax.org/en/latest/config-files.html
                // 	// pass other options into `MathJax.Hub.Config()`
                // 	// TeX: { Macros: macros }
                // },

                // Use local version of katex
                katex: {
                  local: 'dist/katex',
                },
                // Learn about plugins: https://revealjs.com/plugins/
                plugins: [RevealMarkdown, RevealHighlight, RevealNotes, RevealMath.KaTeX]
            });
        </script>
    </body>
</html>
